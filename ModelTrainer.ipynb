{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from transform_image import process\n",
    "import numpy as np\n",
    "import random\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.optimizers import Adam\n",
    "from pyimagesearch.callbacks import EpochCheckpoint\n",
    "from pyimagesearch.callbacks import TrainingMonitor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skin tone\n",
    "lower = np.array([0, 48, 80], dtype = \"uint8\")\n",
    "upper = np.array([20, 255, 255], dtype = \"uint8\")\n",
    "    \n",
    "def mask(x):\n",
    "    converted = cv2.cvtColor(x, cv2.COLOR_BGR2HSV)\n",
    "    skinMask = cv2.inRange(converted, lower, upper)\n",
    "    skinMask = cv2.GaussianBlur(skinMask, (7, 7), 0)\n",
    "    return skinMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to get and save images\n",
    "dPath = \"./Data/\"\n",
    "\n",
    "#Folder names\n",
    "folders = [\"forks\", \"left\", \"stop\", \"peace\", \"right\"]\n",
    "\n",
    "#Gesture dictionary\n",
    "gesture = {'forks':0,'left':1,'stop':2,'peace':3, 'right':4}\n",
    "\n",
    "#Train Test data storage\n",
    "X_train = []\n",
    "y_train =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im = cv2.imread(dPath + folders[0] + \"/\" + \"forks(1).jpg\")\n",
    "# im = cv2.resize(im, dsize=(50,50))\n",
    "# im = mask(im)\n",
    "# cv2.imshow('im',im)\n",
    "# cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "broke = 0\n",
    "#Load in our training data with a testtrain split\n",
    "for folder in folders:\n",
    "    listing = os.listdir(dPath + folder)\n",
    "    for file in listing:\n",
    "        #Import and process image into mask\n",
    "        im = cv2.imread(dPath + folder + \"/\" + file)\n",
    "            \n",
    "        if im is not None:\n",
    "            im = cv2.resize(im, dsize=(50,50))\n",
    "            im = mask(im)\n",
    "\n",
    "            im = np.asarray(im)/255\n",
    "            im = np.expand_dims(im,axis=2)\n",
    "            X_train.append(im)\n",
    "            y_val = np.zeros(len(folders))\n",
    "            y_val[gesture[folder]] = 1\n",
    "            y_train.append(y_val)\n",
    "        \n",
    "        else: \n",
    "            broke = broke + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert lists to numpy arrays\n",
    "X = np.asarray(X_train)\n",
    "y = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "inputShape = (50,50,1)\n",
    "chanDim = 2\n",
    "reg = l2(0.001)\n",
    "\n",
    "# Start model\n",
    "model = Sequential()\n",
    "\n",
    "# Block #1: first CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",kernel_initializer=\"he_normal\", input_shape=inputShape))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(32, (3, 3), kernel_initializer=\"he_normal\",padding=\"same\"))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Block #2: second CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(64, (3, 3), kernel_initializer=\"he_normal\",padding=\"same\"))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(64, (3, 3), kernel_initializer=\"he_normal\",padding=\"same\"))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Block #3: third CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(128, (3, 3), kernel_initializer=\"he_normal\",padding=\"same\"))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(128, (3, 3), kernel_initializer=\"he_normal\",padding=\"same\"))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Block #4: first set of FC => RELU layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, kernel_initializer=\"he_normal\"))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Block #6: second set of FC => RELU layers\n",
    "model.add(Dense(64, kernel_initializer=\"he_normal\"))\n",
    "model.add(ELU())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Block #7: softmax classifier\n",
    "model.add(Dense(5, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "#Create the model\n",
    "#model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "opt = Adam(lr=1e-3)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "# construct the set of callbacks\n",
    "figPath = os.path.sep.join([\"outputs\",\"vggnet_emotion.png\"])\n",
    "jsonPath = os.path.sep.join([\"outputs\",\"vggnet_emotion.json\"])\n",
    "callbacks = [EpochCheckpoint(\"checkpoints\", every=5,startAt=epoch),TrainingMonitor(figPath, jsonPath=jsonPath,startAt=epoch)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 19952 samples, validate on 8552 samples\n",
      "Epoch 1/40\n",
      "19952/19952 [==============================] - 379s 19ms/step - loss: 0.9592 - acc: 0.6500 - val_loss: 0.3340 - val_acc: 0.8845\n",
      "Epoch 2/40\n",
      "19952/19952 [==============================] - 369s 18ms/step - loss: 0.3891 - acc: 0.8702 - val_loss: 0.1728 - val_acc: 0.9426\n",
      "Epoch 3/40\n",
      "19952/19952 [==============================] - 374s 19ms/step - loss: 0.2573 - acc: 0.9176 - val_loss: 0.1275 - val_acc: 0.9559\n",
      "Epoch 4/40\n",
      "19952/19952 [==============================] - 354s 18ms/step - loss: 0.1990 - acc: 0.9384 - val_loss: 0.1039 - val_acc: 0.9681\n",
      "Epoch 5/40\n",
      "19952/19952 [==============================] - 364s 18ms/step - loss: 0.1576 - acc: 0.9507 - val_loss: 0.1028 - val_acc: 0.9689\n",
      "Epoch 6/40\n",
      "19952/19952 [==============================] - 387s 19ms/step - loss: 0.1370 - acc: 0.9574 - val_loss: 0.0957 - val_acc: 0.9723\n",
      "Epoch 7/40\n",
      "19952/19952 [==============================] - 424s 21ms/step - loss: 0.1226 - acc: 0.9619 - val_loss: 0.0957 - val_acc: 0.9702\n",
      "Epoch 8/40\n",
      "19952/19952 [==============================] - 364s 18ms/step - loss: 0.1037 - acc: 0.9685 - val_loss: 0.0951 - val_acc: 0.9714\n",
      "Epoch 9/40\n",
      "19952/19952 [==============================] - 374s 19ms/step - loss: 0.0967 - acc: 0.9693 - val_loss: 0.0788 - val_acc: 0.9768\n",
      "Epoch 10/40\n",
      "19952/19952 [==============================] - 404s 20ms/step - loss: 0.0855 - acc: 0.9732 - val_loss: 0.0659 - val_acc: 0.9811\n",
      "Epoch 11/40\n",
      "19952/19952 [==============================] - 398s 20ms/step - loss: 0.0720 - acc: 0.9772 - val_loss: 0.0778 - val_acc: 0.9761\n",
      "Epoch 12/40\n",
      "19952/19952 [==============================] - 371s 19ms/step - loss: 0.0691 - acc: 0.9786 - val_loss: 0.0838 - val_acc: 0.9757\n",
      "Epoch 13/40\n",
      "19952/19952 [==============================] - 371s 19ms/step - loss: 0.0630 - acc: 0.9795 - val_loss: 0.0749 - val_acc: 0.9777\n",
      "Epoch 14/40\n",
      "19952/19952 [==============================] - 399s 20ms/step - loss: 0.0537 - acc: 0.9836 - val_loss: 0.0645 - val_acc: 0.9821\n",
      "Epoch 15/40\n",
      "19952/19952 [==============================] - 417s 21ms/step - loss: 0.0513 - acc: 0.9841 - val_loss: 0.0673 - val_acc: 0.9812\n",
      "Epoch 16/40\n",
      "19952/19952 [==============================] - 404s 20ms/step - loss: 0.0522 - acc: 0.9837 - val_loss: 0.0729 - val_acc: 0.9806\n",
      "Epoch 17/40\n",
      "19952/19952 [==============================] - 382s 19ms/step - loss: 0.0452 - acc: 0.9844 - val_loss: 0.0616 - val_acc: 0.9833\n",
      "Epoch 18/40\n",
      "19952/19952 [==============================] - 399s 20ms/step - loss: 0.0455 - acc: 0.9861 - val_loss: 0.0684 - val_acc: 0.9818\n",
      "Epoch 19/40\n",
      "19952/19952 [==============================] - 359s 18ms/step - loss: 0.0410 - acc: 0.9867 - val_loss: 0.0790 - val_acc: 0.9800\n",
      "Epoch 20/40\n",
      "19952/19952 [==============================] - 405s 20ms/step - loss: 0.0338 - acc: 0.9896 - val_loss: 0.0643 - val_acc: 0.9827\n",
      "Epoch 21/40\n",
      "19952/19952 [==============================] - 407s 20ms/step - loss: 0.0387 - acc: 0.9884 - val_loss: 0.0562 - val_acc: 0.9848\n",
      "Epoch 22/40\n",
      "19952/19952 [==============================] - 56917s 3s/step - loss: 0.0382 - acc: 0.9888 - val_loss: 0.0564 - val_acc: 0.9848\n",
      "Epoch 23/40\n",
      "19952/19952 [==============================] - 380s 19ms/step - loss: 0.0301 - acc: 0.9909 - val_loss: 0.0612 - val_acc: 0.9846\n",
      "Epoch 24/40\n",
      "19952/19952 [==============================] - 381s 19ms/step - loss: 0.0260 - acc: 0.9916 - val_loss: 0.0555 - val_acc: 0.9860\n",
      "Epoch 25/40\n",
      "19952/19952 [==============================] - 391s 20ms/step - loss: 0.0259 - acc: 0.9911 - val_loss: 0.0661 - val_acc: 0.9834\n",
      "Epoch 26/40\n",
      "19952/19952 [==============================] - 368s 18ms/step - loss: 0.0271 - acc: 0.9915 - val_loss: 0.0602 - val_acc: 0.9849\n",
      "Epoch 27/40\n",
      "19952/19952 [==============================] - 366s 18ms/step - loss: 0.0331 - acc: 0.9896 - val_loss: 0.0642 - val_acc: 0.9843\n",
      "Epoch 28/40\n",
      "19952/19952 [==============================] - 378s 19ms/step - loss: 0.0314 - acc: 0.9913 - val_loss: 0.0634 - val_acc: 0.9844\n",
      "Epoch 29/40\n",
      "19952/19952 [==============================] - 416s 21ms/step - loss: 0.0236 - acc: 0.9919 - val_loss: 0.0591 - val_acc: 0.9863\n",
      "Epoch 30/40\n",
      "19952/19952 [==============================] - 384s 19ms/step - loss: 0.0270 - acc: 0.9920 - val_loss: 0.0643 - val_acc: 0.9837\n",
      "Epoch 31/40\n",
      "19952/19952 [==============================] - 375s 19ms/step - loss: 0.0205 - acc: 0.9930 - val_loss: 0.0600 - val_acc: 0.9860\n",
      "Epoch 32/40\n",
      "19952/19952 [==============================] - 364s 18ms/step - loss: 0.0210 - acc: 0.9931 - val_loss: 0.0586 - val_acc: 0.9857\n",
      "Epoch 33/40\n",
      "19952/19952 [==============================] - 382s 19ms/step - loss: 0.0218 - acc: 0.9932 - val_loss: 0.0672 - val_acc: 0.9840\n",
      "Epoch 34/40\n",
      "19952/19952 [==============================] - 391s 20ms/step - loss: 0.0245 - acc: 0.9936 - val_loss: 0.0605 - val_acc: 0.9869\n",
      "Epoch 35/40\n",
      "19952/19952 [==============================] - 395s 20ms/step - loss: 0.0203 - acc: 0.9928 - val_loss: 0.0624 - val_acc: 0.9854\n",
      "Epoch 36/40\n",
      "19952/19952 [==============================] - 374s 19ms/step - loss: 0.0214 - acc: 0.9935 - val_loss: 0.0532 - val_acc: 0.9874\n",
      "Epoch 37/40\n",
      "19952/19952 [==============================] - 372s 19ms/step - loss: 0.0220 - acc: 0.9931 - val_loss: 0.0595 - val_acc: 0.9868\n",
      "Epoch 38/40\n",
      "19952/19952 [==============================] - 368s 18ms/step - loss: 0.0199 - acc: 0.9943 - val_loss: 0.0671 - val_acc: 0.9847\n",
      "Epoch 39/40\n",
      "19952/19952 [==============================] - 412s 21ms/step - loss: 0.0168 - acc: 0.9948 - val_loss: 0.0588 - val_acc: 0.9867\n",
      "Epoch 40/40\n",
      "19952/19952 [==============================] - 362s 18ms/step - loss: 0.0165 - acc: 0.9944 - val_loss: 0.0761 - val_acc: 0.9819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2b2f3a20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "#Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=40, shuffle=True, callbacks=callbacks, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "model.save(\"processed28k(pyimage)5hrs.h5py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
